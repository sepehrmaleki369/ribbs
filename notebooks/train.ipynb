{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e971d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd4854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def sample_pred_at_positions(pred, positions):\n",
    "    r, c = positions[:, 0], positions[:, 1]\n",
    "    r0, c0 = r.floor().long(), c.floor().long()\n",
    "    r1, c1 = r0 + 1, c0 + 1\n",
    "    dr, dc = (r - r0.float()).unsqueeze(1), (c - c0.float()).unsqueeze(1)\n",
    "    H, W = pred.shape\n",
    "    r0, r1 = r0.clamp(0, H - 1), r1.clamp(0, H - 1)\n",
    "    c0, c1 = c0.clamp(0, W - 1), c1.clamp(0, W - 1)\n",
    "    Ia, Ib = pred[r0, c0].unsqueeze(1), pred[r0, c1].unsqueeze(1)\n",
    "    Ic, Id = pred[r1, c0].unsqueeze(1), pred[r1, c1].unsqueeze(1)\n",
    "    val = (Ia * (1 - dr) * (1 - dc) +\n",
    "           Ib * (1 - dr) * dc +\n",
    "           Ic * dr * (1 - dc) +\n",
    "           Id * dr * dc)\n",
    "    return val.squeeze(1)\n",
    "\n",
    "def compute_normals(sdf):\n",
    "    H, W = sdf.shape\n",
    "    grad_row, grad_col = torch.zeros_like(sdf), torch.zeros_like(sdf)\n",
    "    sdf_smoothed = sdf  # add GaussianBlur here if you wish\n",
    "    grad_row[1:-1] = (sdf_smoothed[2:] - sdf_smoothed[:-2]) * 0.5\n",
    "    grad_col[:, 1:-1] = (sdf_smoothed[:, 2:] - sdf_smoothed[:, :-2]) * 0.5\n",
    "    grad_row[0]  = sdf_smoothed[1] - sdf_smoothed[0]\n",
    "    grad_row[-1] = sdf_smoothed[-1] - sdf_smoothed[-2]\n",
    "    grad_col[:, 0]  = sdf_smoothed[:, 1] - sdf_smoothed[:, 0]\n",
    "    grad_col[:, -1] = sdf_smoothed[:, -1] - sdf_smoothed[:, -2]\n",
    "    return torch.stack([grad_row, grad_col], dim=2)  # (H,W,2)\n",
    "\n",
    "def sample_normals_at_positions(normals, positions, normalize=True):\n",
    "    H, W, _ = normals.shape\n",
    "    r, c = positions[:, 0], positions[:, 1]\n",
    "    r0, c0 = r.floor().long(), c.floor().long()\n",
    "    r1, c1 = r0 + 1, c0 + 1\n",
    "    dr, dc = (r - r0.float()).unsqueeze(1), (c - c0.float()).unsqueeze(1)\n",
    "    r0, r1 = r0.clamp(0, H-1), r1.clamp(0, H-1)\n",
    "    c0, c1 = c0.clamp(0, W-1), c1.clamp(0, W-1)\n",
    "    Ia, Ib = normals[r0, c0], normals[r0, c1]\n",
    "    Ic, Id = normals[r1, c0], normals[r1, c1]\n",
    "    n_interp = (Ia * (1 - dr) * (1 - dc) +\n",
    "                Ib * (1 - dr) * dc +\n",
    "                Ic * dr * (1 - dc) +\n",
    "                Id * dr * dc)\n",
    "    if normalize:\n",
    "        n_interp = n_interp / (torch.norm(n_interp, dim=1, keepdim=True) + 1e-8)\n",
    "    return n_interp  # (N,2)\n",
    "\n",
    "def extract_zero_crossings_interpolated_positions(sdf_tensor, requires_grad=False):\n",
    "    eps, pos, H, W = 1e-8, [], *sdf_tensor.shape\n",
    "    sdf_np = sdf_tensor.detach().cpu().numpy()\n",
    "    # vertical neighbours\n",
    "    for i in range(H-1):\n",
    "        for j in range(W):\n",
    "            v1, v2 = sdf_np[i, j], sdf_np[i+1, j]\n",
    "            if v1 == 0:                pos.append([i, j])\n",
    "            elif v2 == 0:              pos.append([i+1, j])\n",
    "            elif v1 * v2 < 0:\n",
    "                alpha = abs(v1) / (abs(v1) + abs(v2) + eps)\n",
    "                pos.append([i + alpha, j])\n",
    "    # horizontal neighbours\n",
    "    for i in range(H):\n",
    "        for j in range(W-1):\n",
    "            v1, v2 = sdf_np[i, j], sdf_np[i, j+1]\n",
    "            if v1 == 0:                pos.append([i, j])\n",
    "            elif v2 == 0:              pos.append([i, j+1])\n",
    "            elif v1 * v2 < 0:\n",
    "                alpha = abs(v1) / (abs(v1) + abs(v2) + eps)\n",
    "                pos.append([i, j + alpha])\n",
    "    return (torch.tensor(pos, dtype=torch.float32, device=sdf_tensor.device,\n",
    "                         requires_grad=requires_grad)\n",
    "            if pos else\n",
    "            torch.empty((0, 2), dtype=torch.float32, device=sdf_tensor.device,\n",
    "                        requires_grad=requires_grad))\n",
    "\n",
    "def compute_chamfer_distance(points1, points2):\n",
    "    if points1.numel() == 0 or points2.numel() == 0:\n",
    "        return torch.tensor(float('inf'), device=points1.device)\n",
    "    dists = torch.norm(points1.unsqueeze(1) - points2.unsqueeze(0), dim=2)\n",
    "    return -torch.min(dists, dim=1).values.mean() + torch.min(dists, dim=0).values.mean()\n",
    "\n",
    "def manual_chamfer_grad(pred_sdf, pred_zc, gt_zc, update_scale=1.0, dist_threshold=3.0):\n",
    "    dSDF = torch.zeros_like(pred_sdf)\n",
    "    normals = compute_normals(pred_sdf)\n",
    "    n_at_pts = sample_normals_at_positions(normals, pred_zc)  # (N,2)\n",
    "    gt_cpu, pred_cpu = gt_zc.detach().cpu(), pred_zc.detach().cpu()\n",
    "    for i, p in enumerate(pred_cpu):\n",
    "        dists = torch.norm(gt_cpu - p, dim=1)\n",
    "        min_dist, idx = torch.min(dists, dim=0)\n",
    "        if min_dist > dist_threshold:  # ignore spurious prediction\n",
    "            continue\n",
    "        dl_dp = gt_cpu[idx] - p                       # (2,)\n",
    "        n = n_at_pts[i] / (torch.norm(n_at_pts[i]) + 1e-8)\n",
    "        dot_val = torch.dot(dl_dp.to(n.device), n) * update_scale\n",
    "        r, c = p.tolist()\n",
    "        r0, c0 = int(np.floor(r)), int(np.floor(c))\n",
    "        r1, c1 = r0 + 1, c0 + 1\n",
    "        w_r1, w_c1 = r - r0, c - c0\n",
    "        w_r0, w_c0 = 1 - w_r1, 1 - w_c1\n",
    "        H, W = dSDF.shape\n",
    "        if 0 <= r0 < H and 0 <= c0 < W: dSDF[r0, c0] += dot_val * w_r0 * w_c0\n",
    "        if 0 <= r0 < H and 0 <= c1 < W: dSDF[r0, c1] += dot_val * w_r0 * w_c1\n",
    "        if 0 <= r1 < H and 0 <= c0 < W: dSDF[r1, c0] += dot_val * w_r1 * w_c0\n",
    "        if 0 <= r1 < H and 0 <= c1 < W: dSDF[r1, c1] += dot_val * w_r1 * w_c1\n",
    "    return dSDF\n",
    "\n",
    "\n",
    "\n",
    "class ChamferBoundarySDFLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Final loss =  pixel_weight * L1(pred, gt)  with an additional boundary\n",
    "    gradient injected (chamfer_weight * manual_chamfer_grad).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 pixel_weight: float   = 1.0,\n",
    "                 chamfer_weight: float = 1.0,\n",
    "                 update_scale: float   = 100.0,\n",
    "                 dist_threshold: float = 1.5):\n",
    "        super().__init__()\n",
    "        self.pixel_w      = pixel_weight\n",
    "        self.chamfer_w    = chamfer_weight\n",
    "        self.update_scale = update_scale\n",
    "        self.dist_thresh  = dist_threshold\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    def forward(self, pred_logits: torch.Tensor, gt_sdf: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        pred_logits : (B,1,H,W)  raw UNet outputs (interpreted as SDF)\n",
    "        gt_sdf      : (B,1,H,W) or (B,H,W)  ground‑truth SDF\n",
    "        returns     : scalar loss\n",
    "        \"\"\"\n",
    "        if pred_logits.ndim != 4 or pred_logits.size(1) != 1:\n",
    "            raise ValueError(\"pred_logits must be (B,1,H,W)\")\n",
    "        pred_sdf = pred_logits[:, 0]          # (B,H,W)\n",
    "\n",
    "        if gt_sdf.ndim == 4 and gt_sdf.size(1) == 1:\n",
    "            gt_sdf = gt_sdf[:, 0]             # (B,H,W)\n",
    "        elif gt_sdf.ndim != 3:\n",
    "            raise ValueError(\"gt_sdf must be (B,1,H,W) or (B,H,W)\")\n",
    "\n",
    "        # 1) pixel loss (fully differentiable)\n",
    "        pixel_loss = F.l1_loss(pred_sdf, gt_sdf)\n",
    "\n",
    "        # 2) inject boundary gradient via register_hook\n",
    "        chamfer_vals = []\n",
    "        for b in range(pred_sdf.size(0)):\n",
    "            psdf, gsdf = pred_sdf[b], gt_sdf[b]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                gt_zc   = extract_zero_crossings_interpolated_positions(gsdf, False)\n",
    "                pred_zc = extract_zero_crossings_interpolated_positions(psdf, True)\n",
    "\n",
    "            dSDF = manual_chamfer_grad(psdf, pred_zc, gt_zc,\n",
    "                                       update_scale=self.update_scale,\n",
    "                                       dist_threshold=self.dist_thresh)\n",
    "\n",
    "            psdf.register_hook(lambda g, d=dSDF: g + self.chamfer_w * d)\n",
    "            chamfer_vals.append(compute_chamfer_distance(pred_zc, gt_zc))\n",
    "\n",
    "        # 3) composite value (only pixel_loss contributes numerically)\n",
    "        loss = self.pixel_w * pixel_loss\n",
    "\n",
    "        # store for optional logging\n",
    "        self.last_pixel   = pixel_loss.detach()\n",
    "        self.last_chamfer = (torch.stack(chamfer_vals).mean().detach()\n",
    "                             if chamfer_vals else torch.tensor(0.0))\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593dd779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses/chamfer_boundary_sdf.py\n",
    "# ----------------------------------------------------------\n",
    "# ChamferBoundarySDFLoss: top-tier, memory-safe, vectorized\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# Utility functions\n",
    "# ==========================================================\n",
    "\n",
    "def subsample_points(pts: torch.Tensor, max_points: int) -> torch.Tensor:\n",
    "    \"\"\"Randomly subsample points if they exceed max_points.\"\"\"\n",
    "    if pts.numel() == 0 or pts.size(0) <= max_points:\n",
    "        return pts\n",
    "    idx = torch.randperm(pts.size(0), device=pts.device)[:max_points]\n",
    "    return pts[idx]\n",
    "\n",
    "\n",
    "def chunked_min_pairwise(a: torch.Tensor,\n",
    "                         b: torch.Tensor,\n",
    "                         chunk: int = 2048) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Compute min pairwise distances a->b and b->a in chunks to avoid OOM.\n",
    "    a: (Na,2), b: (Nb,2)\n",
    "    Returns:\n",
    "        mins_ab: (Na,)  each element is min distance from a[i] to any point in b\n",
    "        mins_ba: (Nb,)  same but from b[j] to any point in a\n",
    "    \"\"\"\n",
    "    if a.numel() == 0 or b.numel() == 0:\n",
    "        dev = a.device if a.numel() else b.device\n",
    "        na = a.size(0)\n",
    "        nb = b.size(0)\n",
    "        mins_ab = torch.full((na,), float('inf'), device=dev)\n",
    "        mins_ba = torch.full((nb,), float('inf'), device=dev)\n",
    "        return mins_ab, mins_ba\n",
    "\n",
    "    mins_ab = []\n",
    "    for s in range(0, a.size(0), chunk):\n",
    "        d = torch.cdist(a[s:s + chunk], b)\n",
    "        mins_ab.append(d.min(dim=1).values)\n",
    "    mins_ab = torch.cat(mins_ab, dim=0)\n",
    "\n",
    "    mins_ba = []\n",
    "    for s in range(0, b.size(0), chunk):\n",
    "        d = torch.cdist(b[s:s + chunk], a)\n",
    "        mins_ba.append(d.min(dim=1).values)\n",
    "    mins_ba = torch.cat(mins_ba, dim=0)\n",
    "\n",
    "    return mins_ab, mins_ba\n",
    "\n",
    "\n",
    "def bilinear_sample(image: torch.Tensor, pos: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Bilinear sample a 2D tensor image(H,W) at N floating positions pos(N,2).\n",
    "    pos[:,0] = row (y), pos[:,1] = col (x).\n",
    "    Returns (N,).\n",
    "    \"\"\"\n",
    "    r, c = pos[:, 0], pos[:, 1]\n",
    "    r0 = torch.floor(r).long()\n",
    "    c0 = torch.floor(c).long()\n",
    "    r1 = r0 + 1\n",
    "    c1 = c0 + 1\n",
    "\n",
    "    H, W = image.shape\n",
    "    r0 = r0.clamp(0, H - 1)\n",
    "    r1 = r1.clamp(0, H - 1)\n",
    "    c0 = c0.clamp(0, W - 1)\n",
    "    c1 = c1.clamp(0, W - 1)\n",
    "\n",
    "    dr = (r - r0.float()).unsqueeze(1)\n",
    "    dc = (c - c0.float()).unsqueeze(1)\n",
    "\n",
    "    Ia = image[r0, c0].unsqueeze(1)\n",
    "    Ib = image[r0, c1].unsqueeze(1)\n",
    "    Ic = image[r1, c0].unsqueeze(1)\n",
    "    Id = image[r1, c1].unsqueeze(1)\n",
    "\n",
    "    val = (Ia * (1 - dr) * (1 - dc) +\n",
    "           Ib * (1 - dr) * dc +\n",
    "           Ic * dr * (1 - dc) +\n",
    "           Id * dr * dc)\n",
    "    return val.squeeze(1)\n",
    "\n",
    "\n",
    "def finite_diff_normals(sdf: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute normals via central differences.\n",
    "    sdf: (H,W)\n",
    "    returns: (H,W,2) -> grad_row, grad_col\n",
    "    \"\"\"\n",
    "    H, W = sdf.shape\n",
    "    grad_row = torch.zeros_like(sdf)\n",
    "    grad_col = torch.zeros_like(sdf)\n",
    "\n",
    "    grad_row[1:-1] = (sdf[2:] - sdf[:-2]) * 0.5\n",
    "    grad_col[:, 1:-1] = (sdf[:, 2:] - sdf[:, :-2]) * 0.5\n",
    "\n",
    "    grad_row[0] = sdf[1] - sdf[0]\n",
    "    grad_row[-1] = sdf[-1] - sdf[-2]\n",
    "    grad_col[:, 0] = sdf[:, 1] - sdf[:, 0]\n",
    "    grad_col[:, -1] = sdf[:, -1] - sdf[:, -2]\n",
    "\n",
    "    return torch.stack([grad_row, grad_col], dim=2)\n",
    "\n",
    "\n",
    "def bilinear_sample_normals(normals: torch.Tensor,\n",
    "                            pos: torch.Tensor,\n",
    "                            normalize: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Bilinearly sample normals(H,W,2) at positions(N,2).\n",
    "    returns (N,2).\n",
    "    \"\"\"\n",
    "    H, W, _ = normals.shape\n",
    "    r, c = pos[:, 0], pos[:, 1]\n",
    "    r0 = torch.floor(r).long()\n",
    "    c0 = torch.floor(c).long()\n",
    "    r1 = r0 + 1\n",
    "    c1 = c0 + 1\n",
    "\n",
    "    r0 = r0.clamp(0, H - 1)\n",
    "    r1 = r1.clamp(0, H - 1)\n",
    "    c0 = c0.clamp(0, W - 1)\n",
    "    c1 = c1.clamp(0, W - 1)\n",
    "\n",
    "    dr = (r - r0.float()).unsqueeze(1)\n",
    "    dc = (c - c0.float()).unsqueeze(1)\n",
    "\n",
    "    Ia = normals[r0, c0]\n",
    "    Ib = normals[r0, c1]\n",
    "    Ic = normals[r1, c0]\n",
    "    Id = normals[r1, c1]\n",
    "\n",
    "    n = (Ia * (1 - dr) * (1 - dc) +\n",
    "         Ib * (1 - dr) * dc +\n",
    "         Ic * dr * (1 - dc) +\n",
    "         Id * dr * dc)\n",
    "\n",
    "    if normalize:\n",
    "        n = n / (torch.norm(n, dim=1, keepdim=True) + 1e-8)\n",
    "    return n\n",
    "\n",
    "\n",
    "def extract_zero_crossings(sdf: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Fully vectorized zero-crossing extraction for a single 2D SDF image.\n",
    "    sdf: (H,W)\n",
    "    returns: (N,2) tensor of subpixel coordinates (row, col).\n",
    "    \"\"\"\n",
    "    device = sdf.device\n",
    "    dtype = sdf.dtype\n",
    "    eps = 1e-8\n",
    "\n",
    "    H, W = sdf.shape\n",
    "\n",
    "    # vertical sign changes between rows\n",
    "    v1 = sdf[:-1, :]     # (H-1,W)\n",
    "    v2 = sdf[1:, :]      # (H-1,W)\n",
    "    sign_change_v = (v1 * v2) < 0\n",
    "    nonzero_v1 = (v1 == 0)\n",
    "    nonzero_v2 = (v2 == 0)\n",
    "\n",
    "    idx_v = sign_change_v.nonzero(as_tuple=False)\n",
    "    # idx_v: (Nv, 2) -> [r, c] where r in [0,H-2]\n",
    "    if idx_v.numel():\n",
    "        r = idx_v[:, 0]\n",
    "        c = idx_v[:, 1]\n",
    "        a = torch.abs(v1[r, c])\n",
    "        b = torch.abs(v2[r, c])\n",
    "        alpha = a / (a + b + eps)\n",
    "        rows = r.float() + alpha\n",
    "        cols = c.float()\n",
    "        vert_pts = torch.stack([rows, cols], dim=1)\n",
    "    else:\n",
    "        vert_pts = torch.empty((0, 2), device=device, dtype=dtype)\n",
    "\n",
    "    # handle exact zero in vertical neighbors\n",
    "    z_idx_v1 = nonzero_v1.nonzero(as_tuple=False)\n",
    "    z_idx_v2 = nonzero_v2.nonzero(as_tuple=False)\n",
    "    if z_idx_v1.numel():\n",
    "        vert_zero1 = torch.stack([z_idx_v1[:, 0].float(),\n",
    "                                  z_idx_v1[:, 1].float()], dim=1)\n",
    "        vert_pts = torch.cat([vert_pts, vert_zero1], dim=0)\n",
    "    if z_idx_v2.numel():\n",
    "        vert_zero2 = torch.stack([z_idx_v2[:, 0].float() + 1,\n",
    "                                  z_idx_v2[:, 1].float()], dim=1)\n",
    "        vert_pts = torch.cat([vert_pts, vert_zero2], dim=0)\n",
    "\n",
    "    # horizontal sign changes between columns\n",
    "    h1 = sdf[:, :-1]     # (H,W-1)\n",
    "    h2 = sdf[:,  1:]     # (H,W-1)\n",
    "    sign_change_h = (h1 * h2) < 0\n",
    "    nonzero_h1 = (h1 == 0)\n",
    "    nonzero_h2 = (h2 == 0)\n",
    "\n",
    "    idx_h = sign_change_h.nonzero(as_tuple=False)\n",
    "    if idx_h.numel():\n",
    "        r = idx_h[:, 0]\n",
    "        c = idx_h[:, 1]\n",
    "        a = torch.abs(h1[r, c])\n",
    "        b = torch.abs(h2[r, c])\n",
    "        alpha = a / (a + b + eps)\n",
    "        rows = r.float()\n",
    "        cols = c.float() + alpha\n",
    "        horiz_pts = torch.stack([rows, cols], dim=1)\n",
    "    else:\n",
    "        horiz_pts = torch.empty((0, 2), device=device, dtype=dtype)\n",
    "\n",
    "    # handle exact zero in horizontal neighbors\n",
    "    z_idx_h1 = nonzero_h1.nonzero(as_tuple=False)\n",
    "    z_idx_h2 = nonzero_h2.nonzero(as_tuple=False)\n",
    "    if z_idx_h1.numel():\n",
    "        horiz_zero1 = torch.stack([z_idx_h1[:, 0].float(),\n",
    "                                   z_idx_h1[:, 1].float()], dim=1)\n",
    "        horiz_pts = torch.cat([horiz_pts, horiz_zero1], dim=0)\n",
    "    if z_idx_h2.numel():\n",
    "        horiz_zero2 = torch.stack([z_idx_h2[:, 0].float(),\n",
    "                                   z_idx_h2[:, 1].float() + 1], dim=1)\n",
    "        horiz_pts = torch.cat([horiz_pts, horiz_zero2], dim=0)\n",
    "\n",
    "    # concatenate and remove duplicates (optional)\n",
    "    if vert_pts.numel() == 0 and horiz_pts.numel() == 0:\n",
    "        return torch.empty((0, 2), device=device, dtype=dtype)\n",
    "\n",
    "    pts = torch.cat([vert_pts, horiz_pts], dim=0)\n",
    "    # optional uniqueness (could be expensive); usually fine without:\n",
    "    # pts = torch.unique(torch.round(pts * 1000) / 1000, dim=0)\n",
    "\n",
    "    return pts\n",
    "\n",
    "\n",
    "def make_dSDF(pred_sdf: torch.Tensor,\n",
    "              pred_zc: torch.Tensor,\n",
    "              gt_zc: torch.Tensor,\n",
    "              update_scale: float,\n",
    "              dist_threshold: float,\n",
    "              normalize_normals: bool,\n",
    "              max_points: int,\n",
    "              clip_val: Optional[float]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create the additive gradient field dSDF to be injected.\n",
    "    \"\"\"\n",
    "    if pred_zc.numel() == 0 or gt_zc.numel() == 0:\n",
    "        return torch.zeros_like(pred_sdf)\n",
    "\n",
    "    # optional subsample for safety\n",
    "    pred_zc = subsample_points(pred_zc, max_points)\n",
    "    gt_zc   = subsample_points(gt_zc,   max_points)\n",
    "\n",
    "    normals = finite_diff_normals(pred_sdf)\n",
    "    n_at_pts = bilinear_sample_normals(normals, pred_zc, normalize=normalize_normals)\n",
    "\n",
    "    # Compute nearest GT point for each pred point\n",
    "    # We'll do it chunked:\n",
    "    device = pred_sdf.device\n",
    "    dSDF = torch.zeros_like(pred_sdf)\n",
    "\n",
    "    # Move pred_zc to CPU for loop? We keep it on GPU; we only iterate minimal times\n",
    "    # but do operations in vectorized chunk fashion:\n",
    "    chunk = 2048\n",
    "    for s in range(0, pred_zc.size(0), chunk):\n",
    "        p_chunk = pred_zc[s:s + chunk]          # (C,2)\n",
    "        n_chunk = n_at_pts[s:s + chunk]         # (C,2)\n",
    "        dist = torch.cdist(p_chunk, gt_zc)      # (C, G)\n",
    "        min_dist, idx = dist.min(dim=1)         # (C,)\n",
    "        mask = min_dist <= dist_threshold\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        valid_p = p_chunk[mask]\n",
    "        valid_n = n_chunk[mask]\n",
    "        valid_g = gt_zc[idx[mask]]\n",
    "\n",
    "        # direction from pred to gt\n",
    "        dl_dp = (valid_g - valid_p)             # (M,2)\n",
    "        if normalize_normals:\n",
    "            valid_n = valid_n / (torch.norm(valid_n, dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "        dot_val = torch.sum(dl_dp * valid_n, dim=1) * update_scale  # (M,)\n",
    "\n",
    "        # scatter into dSDF with bilinear weights\n",
    "        r = valid_p[:, 0]\n",
    "        c = valid_p[:, 1]\n",
    "        r0 = torch.floor(r).long().clamp(0, pred_sdf.shape[0] - 1)\n",
    "        c0 = torch.floor(c).long().clamp(0, pred_sdf.shape[1] - 1)\n",
    "        r1 = (r0 + 1).clamp(0, pred_sdf.shape[0] - 1)\n",
    "        c1 = (c0 + 1).clamp(0, pred_sdf.shape[1] - 1)\n",
    "\n",
    "        dr = (r - r0.float())\n",
    "        dc = (c - c0.float())\n",
    "        w00 = (1 - dr) * (1 - dc)\n",
    "        w01 = (1 - dr) * dc\n",
    "        w10 = dr * (1 - dc)\n",
    "        w11 = dr * dc\n",
    "\n",
    "        # accumulation\n",
    "        dSDF.index_put_((r0, c0), dot_val * w00, accumulate=True)\n",
    "        dSDF.index_put_((r0, c1), dot_val * w01, accumulate=True)\n",
    "        dSDF.index_put_((r1, c0), dot_val * w10, accumulate=True)\n",
    "        dSDF.index_put_((r1, c1), dot_val * w11, accumulate=True)\n",
    "\n",
    "    if clip_val is not None:\n",
    "        dSDF = torch.clamp(dSDF, -clip_val, clip_val)\n",
    "\n",
    "    return dSDF\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# Main loss\n",
    "# ==========================================================\n",
    "\n",
    "class ChamferBoundarySDFLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Final loss = pixel_weight * L1(pred_sdf, gt_sdf).\n",
    "\n",
    "    Additionally, a custom gradient term (dSDF) is injected during backward\n",
    "    to align the predicted zero-level set to the ground truth boundary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pixel_weight       : weight of the pixel L1 term\n",
    "    chamfer_weight     : scales the injected gradient (hook)\n",
    "    update_scale       : multiplier inside dSDF construction\n",
    "    dist_threshold     : maximum distance (in px) to consider for Chamfer pairing\n",
    "    max_points         : subsample count of zero-crossing points (pred & gt)\n",
    "    normalize_normals  : normalize normals before dot product\n",
    "    use_hook           : True => inject gradient via register_hook\n",
    "    clip_sdf_to        : clamp both pred and gt SDF to [lo,hi] before loss\n",
    "    clip_dSDF          : clamp dSDF values to [-clip_dSDF, +clip_dSDF]\n",
    "    warmup_factor      : 0..1 external scalar to scale chamfer_weight (set with set_epoch or manually)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 pixel_weight: float = 1.0,\n",
    "                 chamfer_weight: float = 1.0,\n",
    "                 update_scale: float = 100.0,\n",
    "                 dist_threshold: float = 1.0,\n",
    "                 max_points: int = 4096,\n",
    "                 normalize_normals: bool = True,\n",
    "                 use_hook: bool = True,\n",
    "                 clip_sdf_to: Optional[Tuple[float, float]] = None,\n",
    "                 clip_dSDF: Optional[float] = 1.0):\n",
    "        super().__init__()\n",
    "        self.pixel_weight = pixel_weight\n",
    "        self.chamfer_weight = chamfer_weight\n",
    "        self.update_scale = update_scale\n",
    "        self.dist_threshold = dist_threshold\n",
    "        self.max_points = max_points\n",
    "        self.normalize_normals = normalize_normals\n",
    "        self.use_hook = use_hook\n",
    "        self.clip_sdf_to = clip_sdf_to\n",
    "        self.clip_dSDF = clip_dSDF\n",
    "\n",
    "        self._warmup = 1.0  # external multiplier you can change per epoch\n",
    "\n",
    "        # Logging holders\n",
    "        self.last_pixel = torch.tensor(0.0)\n",
    "        self.last_chamfer = torch.tensor(0.0)\n",
    "\n",
    "    # Optional: allow external warmup control\n",
    "    def set_warmup_factor(self, factor: float):\n",
    "        self._warmup = float(factor)\n",
    "\n",
    "    def forward(self, pred_logits: torch.Tensor, gt_sdf: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        pred_logits: (B,1,H,W) raw network output interpreted as SDF\n",
    "        gt_sdf     : (B,1,H,W) or (B,H,W)\n",
    "        \"\"\"\n",
    "        if pred_logits.ndim != 4 or pred_logits.size(1) != 1:\n",
    "            raise ValueError(\"pred_logits must be (B,1,H,W)\")\n",
    "\n",
    "        pred_sdf = pred_logits[:, 0]  # (B,H,W)\n",
    "        if gt_sdf.ndim == 4 and gt_sdf.size(1) == 1:\n",
    "            gt_sdf = gt_sdf[:, 0]\n",
    "        elif gt_sdf.ndim != 3:\n",
    "            raise ValueError(\"gt_sdf must be (B,1,H,W) or (B,H,W)\")\n",
    "\n",
    "        if self.clip_sdf_to is not None:\n",
    "            lo, hi = self.clip_sdf_to\n",
    "            pred_sdf = pred_sdf.clamp(lo, hi)\n",
    "            gt_sdf = gt_sdf.clamp(lo, hi)\n",
    "\n",
    "        # Pixel-wise L1\n",
    "        pixel_loss = F.l1_loss(pred_sdf, gt_sdf)\n",
    "\n",
    "        chamfer_vals = []\n",
    "        if self.use_hook and self._warmup > 0 and self.chamfer_weight > 0:\n",
    "            # build dSDF per image and attach hook\n",
    "            for b in range(pred_sdf.size(0)):\n",
    "                psdf = pred_sdf[b]\n",
    "                gsdf = gt_sdf[b]\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    gt_zc = subsample_points(extract_zero_crossings(gsdf), self.max_points)\n",
    "                    pred_zc = subsample_points(extract_zero_crossings(psdf), self.max_points)\n",
    "\n",
    "                # Only for logging\n",
    "                if pred_zc.numel() and gt_zc.numel():\n",
    "                    d_ab, d_ba = chunked_min_pairwise(pred_zc, gt_zc)\n",
    "                    chamfer_vals.append(-d_ab.mean() + d_ba.mean())\n",
    "                else:\n",
    "                    chamfer_vals.append(psdf.new_tensor(0.0))\n",
    "\n",
    "                if pred_zc.numel() and gt_zc.numel():\n",
    "                    dSDF = make_dSDF(psdf,\n",
    "                                     pred_zc,\n",
    "                                     gt_zc,\n",
    "                                     update_scale=self.update_scale,\n",
    "                                     dist_threshold=self.dist_threshold,\n",
    "                                     normalize_normals=self.normalize_normals,\n",
    "                                     max_points=self.max_points,\n",
    "                                     clip_val=self.clip_dSDF)\n",
    "\n",
    "                    # Inject gradient\n",
    "                    def _hook(grad, d=dSDF):\n",
    "                        return grad + self._warmup * self.chamfer_weight * d\n",
    "\n",
    "                    psdf.register_hook(_hook)\n",
    "        else:\n",
    "            # no hook => chamfer_vals still trackable for logs but not used\n",
    "            chamfer_vals = [pred_sdf.new_tensor(0.0) for _ in range(pred_sdf.size(0))]\n",
    "\n",
    "        self.last_pixel = pixel_loss.detach()\n",
    "        self.last_chamfer = torch.stack(chamfer_vals).mean().detach()\n",
    "\n",
    "        return self.pixel_weight * pixel_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6002c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook cell 1: setup and imports\n",
    "%matplotlib inline\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# from IPython.display import clear_output\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from core.general_dataset.base import GeneralizedDataset\n",
    "from core.general_dataset.collate import worker_init_fn\n",
    "from core.utils import yaml_read\n",
    "from models.base_models import UNet\n",
    "from metrics.apls import APLS\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Configuration\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "DATASET_YAML = \"./configs/dataset/mass_test.yaml\"\n",
    "MODEL_YAML   = \"./configs/model/baseline.yaml\"\n",
    "CKPT_IN      = \"/home/ri/Desktop/Projects/Codebase/AllFayzad/sdf-first-run/outputs/checkpoints/last.ckpt\"\n",
    "\n",
    "BATCH_SIZE   = 1       # effective batch size\n",
    "NUM_EPOCHS   = 100     # total epochs\n",
    "LR           = 1e-4    # learning rate\n",
    "LOG_EVERY    = 1       # log every N batches\n",
    "PLOT_EVERY   = 1       # inline-plot every N epochs\n",
    "NUM_WORKERS  = 4       # DataLoader num_workers\n",
    "\n",
    "CROP_H = 512\n",
    "CROP_W = 512\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Helper to tweak YAML config per split\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def make_cfg(cfg, split):\n",
    "    c = cfg.copy()\n",
    "    c[\"split\"] = split\n",
    "    if split in (\"valid\", \"test\"):\n",
    "        c[\"augmentations\"] = []\n",
    "    return c\n",
    "\n",
    "def center_crop(x: torch.Tensor, crop_h: int, crop_w: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Center‑crop a batched 4‑D tensor x=(B,C,H,W) to size (B, C, crop_h, crop_w).\n",
    "    Assumes crop_h <= H and crop_w <= W.\n",
    "    \"\"\"\n",
    "    _, _, H, W = x.shape\n",
    "    top  = (H - crop_h) // 2\n",
    "    left = (W - crop_w) // 2\n",
    "    return x[:, :, top:top+crop_h, left:left+crop_w]\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Device\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Dataset & DataLoader\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "raw_cfg  = yaml_read(DATASET_YAML)\n",
    "train_ds = GeneralizedDataset(make_cfg(raw_cfg, \"train\"))\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=1,      # load one sample per iteration\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    worker_init_fn=worker_init_fn,\n",
    ")\n",
    "print(f\"Loaded {len(train_ds)} training samples.\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Model instantiation\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "model_cfg = yaml_read(MODEL_YAML)\n",
    "model     = UNet(**model_cfg[\"params\"]).to(device)\n",
    "\n",
    "if os.path.isfile(CKPT_IN):\n",
    "    print(\"Loading checkpoint:\", CKPT_IN)\n",
    "    ckpt_blob = torch.load(CKPT_IN, map_location=device)\n",
    "    state     = ckpt_blob.get(\"state_dict\", ckpt_blob)\n",
    "    state     = {k.replace(\"model.\", \"\"): v for k, v in state.items()}\n",
    "    state     = {k: v for k, v in state.items() if k in model.state_dict()}\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    print(f\"Loaded {len(state)} parameter tensors from checkpoint.\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Loss, metric, optimizer\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "loss_fn = ChamferBoundarySDFLoss(\n",
    "    pixel_weight=1.0,\n",
    "    chamfer_weight=1.0,\n",
    "    update_scale=1.0,\n",
    "    dist_threshold=1.5,\n",
    ").to(device)\n",
    "\n",
    "apls_fn  = APLS(\n",
    "    data_dim=2, threshold=0.5, angle_range=(135,225),\n",
    "    max_nodes=1000, max_snap_dist=4, allow_renaming=True,\n",
    "    min_path_length=10, greater_is_road=True,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Training loop with inline plotting (no AMP)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    if hasattr(train_ds, \"set_epoch\"):\n",
    "        train_ds.set_epoch(epoch)\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_apls = 0.0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_dl, start=1):\n",
    "        x = batch[\"image_patch\"]\n",
    "        y = batch[\"sdf_patch\"]\n",
    "\n",
    "        # center‑crop both so H, W are divisible by 16\n",
    "        x = center_crop(x, CROP_H, CROP_W)\n",
    "        y = center_crop(y, CROP_H, CROP_W)\n",
    "\n",
    "        print('y min', y.min())\n",
    "        # now move to device\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss   = loss_fn(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            probs      = torch.sigmoid(logits)\n",
    "            batch_apls = apls_fn(probs, y)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_apls += batch_apls.item()\n",
    "        global_step  += 1\n",
    "\n",
    "        if batch_idx % LOG_EVERY == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch:03d} | \"\n",
    "                f\"Batch {batch_idx:04d}/{len(train_dl):04d} | \"\n",
    "                f\"Loss {running_loss/batch_idx:.4f} | \"\n",
    "                f\"APLS {running_apls/batch_idx:.4f}\"\n",
    "            )\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dl)\n",
    "    epoch_apls = running_apls / len(train_dl)\n",
    "    print(\n",
    "        f\"===> Epoch {epoch:03d} complete | \"\n",
    "        f\"Avg Loss {epoch_loss:.4f} | Avg APLS {epoch_apls:.4f}\"\n",
    "    )\n",
    "\n",
    "    # inline plotting in notebook\n",
    "    if epoch % PLOT_EVERY == 0:\n",
    "        # clear_output(wait=True)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred_sdf = logits[0, 0].cpu().numpy()\n",
    "            gt_sdf   = y[0, 0].cpu().numpy()\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        ax1.imshow(gt_sdf, cmap='viridis')\n",
    "        ax1.set_title(f'Epoch {epoch}: GT SDF')\n",
    "        ax2.imshow(pred_sdf, cmap='viridis')\n",
    "        ax2.set_title(f'Epoch {epoch}: Predicted SDF')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f998510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Full notebook cell with per‑iteration inline plotting\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output    \n",
    "\n",
    "from core.general_dataset.base import GeneralizedDataset\n",
    "from core.utils import yaml_read\n",
    "from models.base_models import UNet\n",
    "from metrics.apls import APLS\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Config & paths\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "DATASET_YAML = \"./configs/dataset/mass_test.yaml\"\n",
    "MODEL_YAML   = \"./configs/model/baseline.yaml\"\n",
    "CKPT_PATH    = \"/home/ri/Desktop/Projects/Codebase/AllFayzad/sdf-first-run/outputs/checkpoints/last.ckpt\"\n",
    "LR           = 1e-4      # test‑time LR\n",
    "NUM_ITERS    = 20        # refinement steps\n",
    "CROP_SIZE    = 1024       # spatial crop size\n",
    "PLOT_EVERY   = 1         # show after every PLOT_EVERY iterations\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Helper to tweak config per split\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def make_cfg(cfg, split):\n",
    "    c = cfg.copy()\n",
    "    c[\"split\"] = split\n",
    "    if split in (\"valid\", \"test\"):\n",
    "        c[\"augmentations\"] = []\n",
    "    return c\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Device\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Load one validation sample\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "raw_cfg  = yaml_read(DATASET_YAML)\n",
    "valid_ds = GeneralizedDataset(make_cfg(raw_cfg, \"valid\"))\n",
    "sample   = valid_ds[1]\n",
    "x_full   = sample[\"image_patch\"].unsqueeze(0).to(device)  # (1,C,H,W)\n",
    "y_full   = sample[\"sdf_patch\"].unsqueeze(0).to(device)    # (1,1,H,W)\n",
    "_, _, H, W = x_full.shape\n",
    "\n",
    "h0 = (H - CROP_SIZE) // 2\n",
    "w0 = (W - CROP_SIZE) // 2\n",
    "x    = x_full[:, :, h0:h0+CROP_SIZE, w0:w0+CROP_SIZE]\n",
    "y_gt = y_full[:, :, h0:h0+CROP_SIZE, w0:w0+CROP_SIZE]\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Instantiate & load model\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "model_cfg = yaml_read(MODEL_YAML)\n",
    "model     = UNet(**model_cfg[\"params\"]).to(device)\n",
    "ckpt_blob = torch.load(CKPT_PATH, map_location=device)\n",
    "state     = ckpt_blob.get(\"state_dict\", ckpt_blob)\n",
    "state     = {k.replace(\"model.\",\"\"):v for k,v in state.items()}\n",
    "state     = {k:v for k,v in state.items() if k in model.state_dict()}\n",
    "model.load_state_dict(state, strict=False)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Prepare loss & optimizer\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "loss_fn   = ChamferBoundarySDFLoss(1.0, 1.0, 1.0, 0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 4) Inline refinement with per‑iter plotting\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "model.train()\n",
    "losses = []\n",
    "\n",
    "for it in range(1, NUM_ITERS+1):\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(x)\n",
    "    loss   = loss_fn(logits, y_gt)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    if it % PLOT_EVERY == 0:\n",
    "        # clear_output(wait=True)\n",
    "        print(f\"[Iter {it:02d}/{NUM_ITERS:02d}] Loss: {loss.item():.6f}\")\n",
    "\n",
    "        # show GT vs current prediction\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred_sdf = torch.sigmoid(logits)[0,0].cpu().numpy()\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12,5))\n",
    "        ax1.imshow(y_gt[0,0].cpu().numpy(), cmap='seismic')\n",
    "        ax1.set_title(\"Ground Truth SDF\")\n",
    "        ax2.imshow(pred_sdf, cmap='seismic')\n",
    "        ax2.set_title(\"Current Pred SDF\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        model.train()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 5) Final loss curve and SDF comparison\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(range(1, NUM_ITERS+1), losses)\n",
    "plt.xlabel(\"Iteration\"); plt.ylabel(\"Loss\")\n",
    "plt.title(\"Test‑time Refinement Loss\"); plt.show()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_logits = model(x)\n",
    "    final_pred   = torch.sigmoid(final_logits)[0,0].cpu().numpy()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12,5))\n",
    "ax1.imshow(y_gt[0,0].cpu().numpy(), cmap='seismic'); ax1.set_title(\"GT SDF\")\n",
    "ax2.imshow(final_pred, cmap='seismic');   ax2.set_title(\"Refined Pred SDF\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af4dd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b1d45a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d075067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Smoke‑test training loop on two fixed datapoints (100 epochs), no augmentations\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "%matplotlib inline\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from core.general_dataset.base import GeneralizedDataset\n",
    "from core.general_dataset.collate import worker_init_fn\n",
    "from core.utils import yaml_read\n",
    "from models.base_models import UNet\n",
    "from metrics.apls import APLS\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Config paths & hyperparameters\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "DATASET_YAML = \"./configs/dataset/mass_test.yaml\"\n",
    "MODEL_YAML   = \"./configs/model/baseline.yaml\"\n",
    "CKPT_IN      =  \"/home/ri/Desktop/Projects/Codebase/AllFayzad/sdf-first-run/outputs/checkpoints/last.ckpt\"\n",
    "\n",
    "NUM_EPOCHS   = 100\n",
    "LR           = 1e-4\n",
    "NUM_WORKERS  = 0        # no subprocesses for simplicity\n",
    "CROP_H, CROP_W = 512, 512\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Helpers\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def make_cfg(cfg, split):\n",
    "    c = cfg.copy()\n",
    "    c[\"split\"] = split\n",
    "    # valid/test have no augmentations\n",
    "    if split in (\"valid\", \"test\"):\n",
    "        c[\"augmentations\"] = []\n",
    "    return c\n",
    "\n",
    "def center_crop(x: torch.Tensor, crop_h: int, crop_w: int) -> torch.Tensor:\n",
    "    _, _, H, W = x.shape\n",
    "    top  = (H - crop_h) // 2\n",
    "    left = (W - crop_w) // 2\n",
    "    return x[:, :, top:top+crop_h, left:left+crop_w]\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Device\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Build a dataset with NO augmentations by using \"valid\" split\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "raw_cfg = yaml_read(DATASET_YAML)\n",
    "# instantiate with split=\"valid\" so augmentations=[]\n",
    "fixed_ds = GeneralizedDataset(make_cfg(raw_cfg, \"valid\"))\n",
    "\n",
    "# pick two fixed indices for smoke test\n",
    "smoke_ds = Subset(fixed_ds, indices=[0, 1])\n",
    "smoke_dl = DataLoader(\n",
    "    smoke_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    worker_init_fn=worker_init_fn,\n",
    ")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Model, loss, metric, optimizer\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "model_cfg = yaml_read(MODEL_YAML)[\"params\"]\n",
    "model     = UNet(**model_cfg).to(device)\n",
    "\n",
    "if os.path.isfile(CKPT_IN):\n",
    "    ckpt = torch.load(CKPT_IN, map_location=device)\n",
    "    state = ckpt.get(\"state_dict\", ckpt)\n",
    "    state = {k.replace(\"model.\", \"\"): v for k, v in state.items()}\n",
    "    state = {k: v for k, v in state.items() if k in model.state_dict()}\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    print(f\"Loaded {len(state)} tensors from checkpoint.\")\n",
    "\n",
    "loss_fn = ChamferBoundarySDFLoss(\n",
    "    pixel_weight=1.0,\n",
    "    chamfer_weight=1.0,\n",
    "    update_scale=1.0,\n",
    "    dist_threshold=1.5,\n",
    ").to(device)\n",
    "\n",
    "apls_fn = APLS(\n",
    "    data_dim=2, threshold=0.5, angle_range=(135,225),\n",
    "    max_nodes=1000, max_snap_dist=4, allow_renaming=True,\n",
    "    min_path_length=10, greater_is_road=True,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Training loop with inline plotting (100 epochs)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    batch = next(iter(smoke_dl))\n",
    "    x = batch[\"image_patch\"]\n",
    "    y = batch[\"sdf_patch\"]\n",
    "\n",
    "    x = center_crop(x, CROP_H, CROP_W).to(device, non_blocking=True)\n",
    "    y = center_crop(y, CROP_H, CROP_W).to(device, non_blocking=True)\n",
    "\n",
    "    logits = model(x)\n",
    "    loss   = loss_fn(logits, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probs      = torch.sigmoid(logits)\n",
    "        batch_apls = apls_fn(probs, y)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | Loss {loss.item():.4f} | APLS {batch_apls.item():.4f}\")\n",
    "\n",
    "    # Plot GT vs Predicted SDF\n",
    "    gt_sdf   = y[0,0].cpu().numpy()\n",
    "    pred_sdf = logits[0,0].detach().cpu().numpy()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4))\n",
    "    ax1.imshow(gt_sdf, cmap=\"viridis\")\n",
    "    ax1.set_title(f\"Epoch {epoch}: GT SDF\")\n",
    "    ax1.axis(\"off\")\n",
    "    ax2.imshow(pred_sdf, cmap=\"viridis\")\n",
    "    ax2.set_title(f\"Epoch {epoch}: Pred SDF\")\n",
    "    ax2.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # cleanup\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
