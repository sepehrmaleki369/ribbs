# Template
# -----------------------------------------------------------------------------
# Dataset Configuration
# -----------------------------------------------------------------------------
split: "train"             # Which split to load: "train", "valid", or "test"

split_cfg:
  index_save_pth: "/path/to/save_inds.json"
  sources:
    # 1) Folder-based split
    - type: "folder"
      path: "/path/to/root"
      layout: "folders"
      modalities:
        image:
          folder: "sat"
        label:
          folder: "map"
        distance:
          folder: "distance"
        sdf:
          folder: "sdf"
      splits:
        train: "train"
        valid: "valid"
        test:  "test"

    # 2) Ratio-based split
    - type: "ratio"
      layout: "flat"
      path: "/path/to/flat_data"
      modalities:
        image:
          pattern: "^img_(.*)\\.tif$"
        label:
          pattern: "^lbl_(.*)\\.tif$"
      ratios:
        train: 0.7
        valid: 0.15
        test: 0.15

    # 3) K-Fold split
    - type: "kfold"
      layout: "flat"
      path: "/path/to/flat_kfold"
      num_folds: 5
      fold_idx: 0
      seed: 42
      modalities:
        image:
          pattern: "^vol_(.*)\\.npy$"
        label:
          pattern: "^seg_(.*)\\.npy$"
      test_source:
        type: "folder"
        layout: "flat"
        path: "/path/to/kfold_test_data"
        modalities:
          image:
            pattern: "^vol_(.*)\\.npy$"
          label:
            pattern: "^seg_(.*)\\.npy$"

base_modalities:
  - "image"
  - "label"

# -----------------------------------------------------------------------------
# Dimensionality & Patch Extraction
# -----------------------------------------------------------------------------
data_dim: 2                # 2 = 2D patches, 3 = 3D volumes
patch_size: 512            # XY patch size
patch_size_z: 16           # Z-depth (only for 3D)
small_window_size: 8       # window for texture/variance check
validate_road_ratio: false # enforce minimum label coverage
threshold: 0.05            # minimum road fraction if above = true
max_images: null           # limit number of loaded images (null = no limit)
max_attempts: 10           # retries to find a valid patch

# -----------------------------------------------------------------------------
# Computed Modalities
# -----------------------------------------------------------------------------
save_computed: true               # save new distance/SDF files
compute_again_modalities: false   # overwrite existing if true
distance_threshold: 20.0          # clip distance maps (null = no clip)

sdf_iterations: 3                 # dilation iterations before SDF
sdf_thresholds: [-7, 7]           # clip range for SDF values

# -----------------------------------------------------------------------------
# DataLoader Settings
# -----------------------------------------------------------------------------
train_batch_size: 64
val_batch_size: 1
test_batch_size: 1
num_workers: 4
pin_memory: true

# -------------------------------------------------------------------
# Augmentation Pipeline: list of transforms applied at training time
# -------------------------------------------------------------------
augmentations:
  - "flip_h"              # Horizontal flip: mirror left↔right along the X-axis.
  - "flip_v"              # Vertical flip: mirror up↔down along the Y-axis.
  - "rotation"            # Random rotation by a sampled angle in degrees.
  - "scale"               # Isotropic zoom in/out by a sampled scale factor.
  - "elastic"             # Smooth, B-spline–style elastic warp on the grid.
  - "brightness_contrast" # Pixel-wise linear transform: I' = α·I + β.
  - "gamma"               # Gamma correction: I' = (I / I_max)ᵞ · I_max.
  - "gaussian_noise"      # Additive Gaussian noise: N(0, σ_noise·dynamic_range).
  - "gaussian_blur"       # Isotropic Gaussian blur with σ_blur voxels.
  - "bias_field"          # Multiplicative low-frequency field: I' = I · (1 ± amp).

# -------------------------------------------------------------------
# Parameter ranges for each augmentation above
# The code will uniformly sample within these bounds.
# -------------------------------------------------------------------
augmentation_params:
  rotation:
    min: 0.0              # Minimum rotation angle in degrees.
    max: 360.0            # Maximum rotation angle in degrees.

  scale:
    min: 0.8              # Minimum isotropic scale factor (zoom out).
    max: 1.2              # Maximum isotropic scale factor (zoom in).

  elastic:
    alpha_min: 5.0        # Minimum displacement amplitude (voxel units).
    alpha_max: 10.0       # Maximum displacement amplitude.
    sigma_min: 3.0        # Minimum Gaussian smoothing σ for displacement field.
    sigma_max: 6.0        # Maximum Gaussian smoothing σ.

  brightness_contrast:
    alpha_min: 0.9        # Minimum contrast multiplier (darken).
    alpha_max: 1.1        # Maximum contrast multiplier (brighten).
    beta_min: -30.0       # Minimum brightness shift (subtract).
    beta_max: 30.0        # Maximum brightness shift (add).

  gamma:
    min: 0.7              # Minimum gamma exponent (darker shadows).
    max: 1.5              # Maximum gamma exponent (lighter shadows).

  gaussian_noise:
    min: 0.01             # Minimum σ_noise as fraction of image dynamic range.
    max: 0.03             # Maximum σ_noise fraction.

  gaussian_blur:
    min: 0.5              # Minimum blur σ in pixels/voxels.
    max: 1.5              # Maximum blur σ.

  bias_field:
    min: 0.2              # Minimum amplitude of multiplicative bias (1–amp).
    max: 0.4              # Maximum amplitude of multiplicative bias (1+amp).


# -----------------------------------------------------------------------------
# Normalization Settings
# -----------------------------------------------------------------------------
normalization:
  # 1) Min–Max scaling: linearly map [old_min, old_max] → [new_min, new_max]
  image:
    method: "minmax"     # options: minmax, zscore, robust, percentile, clip
    old_min: 0.0         # lower bound of your data range (or null to infer from image)
    old_max: 255.0       # upper bound of your data range (or null to infer from image)
    new_min: 0.0         # target lower bound
    new_max: 1.0         # target upper bound

  # 2) Z-Score normalization: subtract mean, divide by stddev
  distance:
    method: "zscore"     # no extra parameters
    # eps: 1e-8          # optional: minimum stddev to avoid division by zero

  # 3) Robust normalization: clip to [lower_q, upper_q] quantiles, then min–max to [0,1]
  sdf:
    method: "robust"
    lower_q: 0.05        # clip below 5th percentile
    upper_q: 0.95        # clip above 95th percentile

  # 4) Percentile normalization: same as robust but percent arguments in percent units
  #    (i.e., q_low=1.0 means 1st percentile, q_high=99.0 means 99th percentile)
  # sdf:
  #   method: "percentile"
  #   q_low: 1.0
  #   q_high: 99.0

  # 5) Clip normalization: hard-clip to [min_val, max_val], then min–max to [0,1]
  #    Useful if you want to remove outliers or limit range explicitly.
  label:
    method: "clip"
    min_val: 0.0         # clip values below this to 0.0
    max_val: 1.0         # clip values above this to 1.0

  # 6) Skip normalization entirely (e.g. binary labels already in {0,1})
  # label:
  #   method: null        # or simply set `label: null` to bypass


# -----------------------------------------------------------------------------
# Miscellaneous
# -----------------------------------------------------------------------------
seed: 42
verbose: false